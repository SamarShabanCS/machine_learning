{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c5d402-2b32-4002-81c7-bb6f4e774e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b66c050-30c1-4229-982f-d269ffec59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b0c34c8-0584-4aa3-be78-889c40f03609",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from urllib.request import urlopen,urlretrieve\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils\n",
    "from glob import glob\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras import optimizers\n",
    "from keras.models import Sequential,Model,load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D,GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard,ReduceLROnPlateau,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c6fd70-e2b4-4c68-8a59-4164dfea87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnets_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5cdddb-8081-4316-9840-4aa6f242988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if there is a problem\"ImportError: libGL.so.1: cannot open shared object file: No such file or directory\"\n",
    "solve it with:\n",
    "apt-get update\n",
    "apt-get install ffmpeg libsm6 libxext6  -y\n",
    "'''\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432c3d58-bbda-4e98-9856-f0ee9b3c7887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7d682-1c65-4d57-86b7-b5655e9dfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "error: OSError: Unable to open file (file signature not found)\n",
    "sol:file is corrupted.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8724c1a-f2ae-4de4-a689-66deb31ac31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height,img_width = 64,64 \n",
    "num_classes = 6\n",
    "#If imagenet weights are being loaded, \n",
    "#input must have a static square shape (one of (128, 128), (160, 160), (192, 192), or (224, 224))\n",
    "base_model = ResNet50(weights= None, include_top=False, input_shape= (img_height,img_width,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df2c53e7-ee15-4efa-b088-c07113bddd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(num_classes, activation= 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72f7b1f2-24f2-47e3-a58c-ffc2acc599ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer= adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8afd941e-0f88-4add-9741-e7063ebf7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 20s 705ms/step - loss: 3.4899 - accuracy: 0.1907\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 11s 668ms/step - loss: 3.0116 - accuracy: 0.2806\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 12s 693ms/step - loss: 2.7358 - accuracy: 0.3231\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 12s 729ms/step - loss: 2.3551 - accuracy: 0.4028\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 11s 658ms/step - loss: 2.1500 - accuracy: 0.4120\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 12s 704ms/step - loss: 1.7850 - accuracy: 0.5074\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 13s 782ms/step - loss: 1.4349 - accuracy: 0.5972\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 12s 676ms/step - loss: 1.2323 - accuracy: 0.6361\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 0.9538 - accuracy: 0.7231\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 12s 686ms/step - loss: 0.7303 - accuracy: 0.7806\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 11s 664ms/step - loss: 0.5983 - accuracy: 0.8213\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 12s 680ms/step - loss: 0.4986 - accuracy: 0.8509\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 0.3519 - accuracy: 0.8898\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 12s 685ms/step - loss: 0.3452 - accuracy: 0.9037\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 11s 664ms/step - loss: 0.2833 - accuracy: 0.9046\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 11s 659ms/step - loss: 0.2119 - accuracy: 0.9250\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 13s 752ms/step - loss: 0.2465 - accuracy: 0.9241\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 12s 713ms/step - loss: 0.1826 - accuracy: 0.9481\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 12s 707ms/step - loss: 0.1432 - accuracy: 0.9556\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 12s 729ms/step - loss: 0.1394 - accuracy: 0.9565\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 12s 724ms/step - loss: 0.1217 - accuracy: 0.9620\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 12s 694ms/step - loss: 0.1376 - accuracy: 0.9639\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 12s 696ms/step - loss: 0.1129 - accuracy: 0.9657\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 13s 769ms/step - loss: 0.1741 - accuracy: 0.9491\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 13s 780ms/step - loss: 0.1927 - accuracy: 0.9509\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.2216 - accuracy: 0.9417\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.1562 - accuracy: 0.9528\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 15s 892ms/step - loss: 0.1773 - accuracy: 0.9472\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 15s 864ms/step - loss: 0.1270 - accuracy: 0.9685\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 16s 931ms/step - loss: 0.1032 - accuracy: 0.9704\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 15s 898ms/step - loss: 0.1052 - accuracy: 0.9685\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 15s 891ms/step - loss: 0.1342 - accuracy: 0.9676\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 13s 787ms/step - loss: 0.1002 - accuracy: 0.9667\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 12s 713ms/step - loss: 0.0865 - accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 13s 742ms/step - loss: 0.0654 - accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 13s 770ms/step - loss: 0.0754 - accuracy: 0.9796\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 14s 838ms/step - loss: 0.0737 - accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 14s 812ms/step - loss: 0.0579 - accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 14s 836ms/step - loss: 0.0813 - accuracy: 0.9843\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 14s 832ms/step - loss: 0.0611 - accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 15s 874ms/step - loss: 0.0585 - accuracy: 0.9806\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 14s 817ms/step - loss: 0.0511 - accuracy: 0.9843\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 16s 927ms/step - loss: 0.0606 - accuracy: 0.9796\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 14s 843ms/step - loss: 0.0285 - accuracy: 0.9870\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 14s 847ms/step - loss: 0.0474 - accuracy: 0.9824\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 15s 861ms/step - loss: 0.0582 - accuracy: 0.9843\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 14s 826ms/step - loss: 0.0603 - accuracy: 0.9889\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 14s 820ms/step - loss: 0.0401 - accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 15s 851ms/step - loss: 0.0752 - accuracy: 0.9787\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 14s 823ms/step - loss: 0.0571 - accuracy: 0.9870\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 16s 926ms/step - loss: 0.1180 - accuracy: 0.9657\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 14s 846ms/step - loss: 0.0525 - accuracy: 0.9861\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 14s 837ms/step - loss: 0.0744 - accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 15s 864ms/step - loss: 0.0717 - accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 14s 828ms/step - loss: 0.0360 - accuracy: 0.9889\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 15s 868ms/step - loss: 0.0223 - accuracy: 0.9954\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 15s 887ms/step - loss: 0.0237 - accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 15s 884ms/step - loss: 0.0118 - accuracy: 0.9944\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 16s 918ms/step - loss: 0.0238 - accuracy: 0.9954\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 14s 825ms/step - loss: 0.0445 - accuracy: 0.9880\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 14s 838ms/step - loss: 0.0249 - accuracy: 0.9935\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.0349 - accuracy: 0.9917\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0295 - accuracy: 0.9926\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0285 - accuracy: 0.9926\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0386 - accuracy: 0.9898\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.0583 - accuracy: 0.9852\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0195 - accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0435 - accuracy: 0.9870\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 17s 998ms/step - loss: 0.0345 - accuracy: 0.9880\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 17s 990ms/step - loss: 0.0586 - accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0435 - accuracy: 0.9861\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0330 - accuracy: 0.9898\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 17s 988ms/step - loss: 0.0361 - accuracy: 0.9889\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 15s 891ms/step - loss: 0.0543 - accuracy: 0.9889\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 15s 878ms/step - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 0.0348 - accuracy: 0.9889\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 17s 985ms/step - loss: 0.0551 - accuracy: 0.9824\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 17s 975ms/step - loss: 0.0477 - accuracy: 0.9843\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 16s 923ms/step - loss: 0.0463 - accuracy: 0.9843\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0530 - accuracy: 0.9843\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.0414 - accuracy: 0.9880\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 0.0581 - accuracy: 0.9870\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 17s 981ms/step - loss: 0.0435 - accuracy: 0.9833\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 0.0176 - accuracy: 0.9926\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 17s 998ms/step - loss: 0.0185 - accuracy: 0.9907\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 17s 975ms/step - loss: 0.0469 - accuracy: 0.9907\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0546 - accuracy: 0.9843\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 0.0500 - accuracy: 0.9880\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 17s 970ms/step - loss: 0.0344 - accuracy: 0.9935\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0283 - accuracy: 0.9907\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0241 - accuracy: 0.9926\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0446 - accuracy: 0.9880\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 17s 994ms/step - loss: 0.0435 - accuracy: 0.9907\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.0185 - accuracy: 0.9944\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0356 - accuracy: 0.9907\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.0328 - accuracy: 0.9907\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.0406 - accuracy: 0.9861\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.0438 - accuracy: 0.9889\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.0241 - accuracy: 0.9944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f9878fa60>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 100, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d7f5424-a91e-484c-a80d-de80455dd263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 186ms/step - loss: 2.1698 - accuracy: 0.7167\n",
      "Loss = 2.1698391437530518\n",
      "Test Accuracy = 0.7166666388511658\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9a0a769-e4d0-4d22-aa85-74ead40b6c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 32, 32, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 32, 32, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 16, 16, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 16, 16, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 16, 16, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 16, 16, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 16, 16, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 16, 16, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 16, 16, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 16, 16, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 8, 8, 512)    0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 8, 8, 512)    0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 8, 8, 512)    0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 8, 8, 512)    0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 8, 8, 512)    2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 8, 8, 512)    0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 4, 4, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 4, 4, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 4, 4, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 4, 4, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 4, 4, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 4, 4, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 4, 4, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 2, 2, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 2, 2, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 2, 2, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 2, 2, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            12294       dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,600,006\n",
      "Trainable params: 23,546,886\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a623560a-ec73-45e1-bea9-74bd9e3b276c",
   "metadata": {},
   "source": [
    "refrence:\n",
    "https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
